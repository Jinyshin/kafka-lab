package org.example;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Kafka Consumer êµ¬í˜„ì²´
 * click-logs í† í”½ì—ì„œ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * <br>
 * - Consumer: í† í”½ì—ì„œ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
 * - Consumer Group: ì—¬ëŸ¬ Consumerê°€ í˜‘ë ¥í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ë¶„ì‚° ì²˜ë¦¬
 * - íŒŒí‹°ì…˜ ë¶„ë°°: Consumer Group ë‚´ì—ì„œ íŒŒí‹°ì…˜ì„ Consumerë“¤ì—ê²Œ ë¶„ë°°
 * - ì˜¤í”„ì…‹: ê° íŒŒí‹°ì…˜ì—ì„œ Consumerê°€ ì½ì€ ìœ„ì¹˜
 */
public class ClickLogConsumer {
    
    private static final Logger logger = LoggerFactory.getLogger(ClickLogConsumer.class);
    private static final String TOPIC_NAME = "click-logs"; // êµ¬ë…í•  í† í”½ëª…
    
    private final KafkaConsumer<String, String> consumer; // Kafka Consumer ì¸ìŠ¤í„´ìŠ¤
    private final ObjectMapper objectMapper; // JSON ì—­ì§ë ¬í™”ìš©
    private final AtomicInteger messageCount = new AtomicInteger(0); // ì²˜ë¦¬ëœ ë©”ì‹œì§€ ìˆ˜ ì¹´ìš´íŠ¸
    private volatile boolean running = false;
    
    public ClickLogConsumer(String bootstrapServers, String groupId) {
        this.consumer = createConsumer(bootstrapServers, groupId);
        this.objectMapper = new ObjectMapper();
        this.objectMapper.registerModule(new JavaTimeModule());
    }
    
    // Kafka Consumer ì„¤ì • ë° ìƒì„±
    private KafkaConsumer<String, String> createConsumer(String bootstrapServers, String groupId) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); // Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); // Consumer Group ID
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); // í‚¤ ì—­ì§ë ¬í™”
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); // ê°’ ì—­ì§ë ¬í™”
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest"); // ì˜¤í”„ì…‹ì´ ì—†ì„ ë•Œ ì²˜ìŒë¶€í„° ì½ê¸°
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "30000");
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100);
        
        return new KafkaConsumer<>(props);
    }
    
    // ë©”ì‹œì§€ ì†Œë¹„ ì‹œì‘ - Kafkaì˜ í•µì‹¬ Consumer ë¡œì§
    public void startConsuming() {
        consumer.subscribe(Collections.singletonList(TOPIC_NAME)); // í† í”½ êµ¬ë…
        running = true;
        
        logger.info("Starting to consume messages from topic: {}", TOPIC_NAME);
        System.out.println("=== Kafka Click Log Consumer Started ===");
        System.out.println("Listening for messages... (Press Ctrl+C to stop)");
        System.out.println();
        
        try {
            while (running) {
                // Kafkaì—ì„œ ë©”ì‹œì§€ë¥¼ í´ë§(ê°€ì ¸ì˜¤ê¸°) - 1ì´ˆ íƒ€ì„ì•„ì›ƒ
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                // ë°›ì€ ë©”ì‹œì§€ë“¤ì„ í•˜ë‚˜ì”© ì²˜ë¦¬
                for (ConsumerRecord<String, String> record : records) {
                    processMessage(record);
                }
                
                // ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ ì‹œ ì˜¤í”„ì…‹ ì»¤ë°‹ (ì²˜ë¦¬í–ˆë‹¤ê³  í‘œì‹œ)
                if (records.count() > 0) {
                    consumer.commitSync();
                }
            }
        } catch (Exception e) {
            logger.error("Error while consuming messages: {}", e.getMessage(), e);
        } finally {
            consumer.close();
            logger.info("Consumer closed");
        }
    }
    
    // ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ - JSONì„ ê°ì²´ë¡œ ë³€í™˜í•˜ê³  ë¡œê·¸ ì¶œë ¥
    private void processMessage(ConsumerRecord<String, String> record) {
        try {
            ClickLog clickLog = objectMapper.readValue(record.value(), ClickLog.class); // JSON â†’ ê°ì²´ ì—­ì§ë ¬í™”
            int count = messageCount.incrementAndGet();
            
            System.out.println("ğŸ“¨ Message #" + count + " received:");
            System.out.println("   Key: " + record.key());
            System.out.println("   Partition: " + record.partition());
            System.out.println("   Offset: " + record.offset());
            System.out.println("   Click Log: " + clickLog);
            System.out.println("   Raw JSON: " + record.value());
            System.out.println("   ---");
            
            logger.info("Processed message #{} - User: {}, Page: {}, Element: {}", 
                       count, clickLog.getUserId(), clickLog.getPage(), clickLog.getElement());
            
        } catch (Exception e) {
            logger.error("Failed to process message: {}", e.getMessage(), e);
            System.out.println("âŒ Failed to parse message: " + record.value());
            System.out.println("   Error: " + e.getMessage());
            System.out.println("   ---");
        }
    }
    
    public void stop() {
        running = false;
        logger.info("Stop signal received");
    }
    
    public int getMessageCount() {
        return messageCount.get();
    }
}